{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8320e893",
   "metadata": {},
   "source": [
    "## Programming Supplement\n",
    "### Github Link: https://github.com/KKJWang\n",
    "   **Name: Jingkai Wang**\n",
    "   \n",
    "   **The Github Repositories contains many of my projects during my undergraduate courses, including Python, SQL, HTML and so on. Because of the 2-page limit, I copy part of DS4400 projects below.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50471e75",
   "metadata": {},
   "source": [
    "### Import Libraries -- Part of the libraries show here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a3346f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries here\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import confusion_matrix, recall_score, precision_score, f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4916268d",
   "metadata": {},
   "source": [
    "### Ingest data from csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64b4d989",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "data=pd.read_csv('CarPrice_Assignment.csv')\n",
    "# Display the first few rows of the dataframe to understand its structure\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "191c3f6a",
   "metadata": {},
   "source": [
    "### Manage different data type and Wrangle data - Part of Data cleaning of DS4400 project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "369562a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the 'car_ID' column as it's considered useless.\n",
    "data.drop('car_ID', axis=1, inplace=True)\n",
    "\n",
    "# Extract the first part of the 'CarName' column to retain only the car's brand name.\n",
    "data['CarName'] = data['CarName'].str.split(' ', expand=True)[0]\n",
    "\n",
    "# Display the first few rows of the modified DataFrame.\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "410eee42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correct misspelled car brand names in the 'CarName' column using the replace method.\n",
    "data['CarName'] = data['CarName'].replace({'maxda': 'mazda', 'nissan': 'Nissan', 'porcshce': 'porsche', 'toyouta': 'toyota', \n",
    "                            'vokswagen': 'volkswagen', 'vw': 'volkswagen'})\n",
    "# Convert the 'symboling' column to the string data type (categorical).\n",
    "data['symboling'] = data['symboling'].astype('str')\n",
    "\n",
    "# Display the unique values in the 'CarName' column after the corrections.\n",
    "data['CarName'].unique()\n",
    "\n",
    "# Create a list of column names that contain categorical data (object type).\n",
    "categorical_cols = data.select_dtypes(include=['object']).columns\n",
    "\n",
    "# Display the first 5 rows of the DataFrame for the categorical columns.\n",
    "data[categorical_cols].head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fbf361e",
   "metadata": {},
   "source": [
    "### Write your own function -- From classification part of DS4400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63605076",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement the function metrics\n",
    "def metrics(y, ypred):\n",
    "    \"\"\" \n",
    "    Calculate the different metrics for model evaluation\n",
    "    Parameters:\n",
    "        y (pd.series): Actual labels\n",
    "        ypred (pd.series): Predicted outcomes\n",
    "    Returns:\n",
    "        dict: A dictionary include accuracy, sensitivity, specificity, precision, and f1-score\n",
    "    \"\"\"\n",
    "    # Calculate the confusion matrix for the data\n",
    "    tn, fp, fn, tp = confusion_matrix(y, ypred).ravel()\n",
    "    \n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(y, ypred)\n",
    "    sensitivity = recall_score(y, ypred)\n",
    "    specificity = tn / (tn + fp)\n",
    "    precision = precision_score(y, ypred)\n",
    "    f1 = f1_score(y, ypred)\n",
    "\n",
    "    return {'Accuracy': accuracy,\n",
    "            'Sensitivity': sensitivity,\n",
    "            'Specificity': specificity,\n",
    "            'Precision': precision,\n",
    "            'F1_Score': f1}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3baf8367",
   "metadata": {},
   "source": [
    "### Visualize data & Use your function for data analysis -- From Recommendations (end of the DS4400 projects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bd0862d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_decision_boundary(model, X, y, ax, title):\n",
    "    \"\"\"\n",
    "    Plot the SVM decision boundary and support vectors.\n",
    "    \"\"\"\n",
    "    # Create grid to cover feature space\n",
    "    x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "    y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "    x1, y1 = np.meshgrid(np.linspace(x_min, x_max, 100),\n",
    "                         np.linspace(y_min, y_max, 100))\n",
    "\n",
    "    # Predict class labels for each mesh grid point\n",
    "    Z = model.decision_function(np.c_[x1.ravel(), y1.ravel()])\n",
    "    Z = Z.reshape(x1.shape)\n",
    "    \n",
    "    # Plot decision boundary\n",
    "    ax.contour(x1, y1, Z, levels=[0], alpha=0.5, linestyles=['-'])\n",
    "    ax.contourf(x1, y1, Z, levels=[-1, 0, 1], alpha=0.2, colors=['blue', 'gray', 'red'])\n",
    "    ax.scatter(model.support_vectors_[:, 0], model.support_vectors_[:, 1], s=100, facecolors='none', edgecolors='k')\n",
    "    ax.scatter(X[:, 0], X[:, 1], c=y, cmap='autumn')\n",
    "    ax.set_title(title)\n",
    "\n",
    "# Select the first two features from the dataset for visualization\n",
    "X_2D_train = X_train[:, :2]\n",
    "X_2D_test = X_test[:, :2]    \n",
    "\n",
    "# Concatenate the training and test sets along rows for both the features and the target variable\n",
    "X_visualize = np.vstack((X_2D_train, X_2D_test))\n",
    "y_visualize = np.concatenate((y_train, y_test))\n",
    "\n",
    "# Initialize the models with their respective optimal hyperparameters\n",
    "svc_linear_optimal = SVC(kernel='linear', C=grid_search_linear.best_params_['C']).fit(X_visualize, y_visualize)\n",
    "svc_poly_optimal = SVC(kernel='poly', degree=2, C=grid_search_poly.best_params_['C']).fit(X_visualize, y_visualize)\n",
    "svc_rbf_optimal = SVC(kernel='rbf', C=grid_search_rbf.best_params_['C'], gamma=grid_search_rbf.best_params_['gamma']).fit(X_visualize, y_visualize)\n",
    "\n",
    "# Plot decision boundaries and support vectors\n",
    "fig, axes = plt.subplots(nrows=1, ncols=3, figsize=(18, 6))\n",
    "\n",
    "plot_decision_boundary(svc_linear_optimal, X_visualize, y_visualize, axes[0], \"SVM with Linear Kernel\")\n",
    "plot_decision_boundary(svc_poly_optimal, X_visualize, y_visualize, axes[1], \"SVM with Polynomial Kernel\")\n",
    "plot_decision_boundary(svc_rbf_optimal, X_visualize, y_visualize, axes[2], \"SVM with RBF Kernel\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
